{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook I will try to connect to a local model directly from LangChain without using LocalApi\n",
    "Local api is giving me trouble, especially when trying to use GPU.  The performance is much worse than I would expect.  I am going to try to connect directly to the model and see if that helps.\n",
    "\n",
    "https://python.langchain.com/docs/guides/local_llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (0.0.331)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (0.0.60)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (1.26.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kgage\\source\\repos\\personal\\langchaintest\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.15.tar.gz (7.7 MB)\n",
      "     ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.7 MB 10.6 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.9/7.7 MB 17.1 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 3.8/7.7 MB 26.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 6.0/7.7 MB 29.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.7/7.7 MB 31.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Downloading typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Downloading numpy-1.26.1-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.2/61.2 kB ? eta 0:00:00\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.5/45.5 kB ? eta 0:00:00\n",
      "Downloading numpy-1.26.1-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.5/15.8 MB 48.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 3.4/15.8 MB 42.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 5.1/15.8 MB 41.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.7/15.8 MB 43.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.8/15.8 MB 39.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.3/15.8 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 11.7/15.8 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 13.5/15.8 MB 36.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 15.2/15.8 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 38.6 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): started\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): still running...\n",
      "  Building wheel for llama-cpp-python (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.15-cp311-cp311-win_amd64.whl size=1590025 sha256=2cc2c6cbc920cd632dc5e683cdb5e902eed88887489c52e2e7e7fd939a1268e9\n",
      "  Stored in directory: C:\\Users\\kgage\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-aorf8kky\\wheels\\e2\\42\\2a\\b39a4b4219dd3e31a48a7e338d9aae3ee092902cdac988ad36\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: typing-extensions, numpy, diskcache, llama-cpp-python\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.1\n",
      "    Uninstalling numpy-1.26.1:\n",
      "      Successfully uninstalled numpy-1.26.1\n",
      "  Attempting uninstall: diskcache\n",
      "    Found existing installation: diskcache 5.6.3\n",
      "    Uninstalling diskcache-5.6.3:\n",
      "      Successfully uninstalled diskcache-5.6.3\n",
      "  Attempting uninstall: llama-cpp-python\n",
      "    Found existing installation: llama_cpp_python 0.2.15\n",
      "    Uninstalling llama_cpp_python-0.2.15:\n",
      "      Successfully uninstalled llama_cpp_python-0.2.15\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.15 numpy-1.26.1 typing-extensions-4.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain\n",
    "%pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=r\"C:\\Users\\kgage\\source\\repos\\LocalAI\\models\\luna-ai-llama2-uncensored.Q4_0.gguf\",\n",
    "    n_gpu_layers=1,\n",
    "    n_batch=512,\n",
    "    n_ctx=2048,\n",
    "    f16_kv=True,\n",
    "    callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# For someone who has never been to space before, the question \"What was the first man on the moon?\" might seem a bit confusing.➖\n",
      "Step 1: Ask yourself what you know about outer space. Do you know any facts or information related to space exploration? If so, use that knowledge to narrow down your answer. For example, do you know which country was the first to launch a human into space? \n",
      "Step 2: Use your internet search skills and search for \"who was the first man on the moon?\" or \"first lunar landing.\" This will bring up articles, videos, and other resources that can help you answer the question. \n",
      "Step 3: Read through the results and look for information related to the first person to land on the moon. You should be able to find out who he was and when it happened. Some possible answers include Neil Armstrong, Buzz Aldrin, or Michael Collins."
     ]
    },
    {
     "data": {
      "text/plain": [
       "'# For someone who has never been to space before, the question \"What was the first man on the moon?\" might seem a bit confusing.➖\\nStep 1: Ask yourself what you know about outer space. Do you know any facts or information related to space exploration? If so, use that knowledge to narrow down your answer. For example, do you know which country was the first to launch a human into space? \\nStep 2: Use your internet search skills and search for \"who was the first man on the moon?\" or \"first lunar landing.\" This will bring up articles, videos, and other resources that can help you answer the question. \\nStep 3: Read through the results and look for information related to the first person to land on the moon. You should be able to find out who he was and when it happened. Some possible answers include Neil Armstrong, Buzz Aldrin, or Michael Collins.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"The first man on the moon was ... Let's think step by step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I'll try to connect to a local database and run a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "server = '127.0.0.1'\n",
    "database = 'TestDb'\n",
    "username = 'sa'\n",
    "password = 'Password123'\n",
    "driver = 'ODBC Driver 17 for SQL Server'\n",
    "\n",
    "conn_str = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver}\"\n",
    "\n",
    "# Only include the People table\n",
    "db = SQLDatabase.from_uri(conn_str)\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "agent_executor = create_sql_agent(llm=llm, toolkit=toolkit, verbose=True, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "agent_executor.run(\"You have access to a Microsoft SQL server using the langchain toolkit. In the TestDb database how many records are in the People table?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
