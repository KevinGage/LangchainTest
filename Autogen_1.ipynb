{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is part 1 of using autogen with local ai models to query an arbitrary database.\n",
    "In this notebook I will simply connect ChatGPT to a local database and query it.  I will not be using autogen or local AI models\n",
    "I'm using this reference https://github.com/disler/multi-agent-postgres-data-analytics/tree/v1-prompt-engineering-an-entire-codebase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install ODBC Driver for MSSQL\n",
    "If connecting to a SQL database from wsl ubuntu (like this notebook), you will need to install the following packages:\n",
    "```bash\n",
    "sudo apt install unixodbc\n",
    "```\n",
    "\n",
    "Then follow instructions here\n",
    "https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver15&tabs=alpine18-install%2Cubuntu17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline\n",
    "\n",
    "basically run this bash script for version 17 (other versions available see link)\n",
    "```\n",
    "if ! [[ \"16.04 18.04 20.04 22.04\" == *\"$(lsb_release -rs)\"* ]];\n",
    "then\n",
    "    echo \"Ubuntu $(lsb_release -rs) is not currently supported.\";\n",
    "    exit;\n",
    "fi\n",
    "\n",
    "curl https://packages.microsoft.com/keys/microsoft.asc | sudo tee /etc/apt/trusted.gpg.d/microsoft.asc\n",
    "\n",
    "curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list\n",
    "\n",
    "sudo apt-get update\n",
    "sudo ACCEPT_EULA=Y apt-get install -y msodbcsql17\n",
    "# optional: for bcp and sqlcmd\n",
    "sudo ACCEPT_EULA=Y apt-get install -y mssql-tools\n",
    "echo 'export PATH=\"$PATH:/opt/mssql-tools/bin\"' >> ~/.bashrc\n",
    "source ~/.bashrc\n",
    "# optional: for unixODBC development headers\n",
    "sudo apt-get install -y unixodbc-dev\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in ./.venv/lib/python3.10/site-packages (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openai==0.28.1\n",
      "  Using cached openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests>=2.20 (from openai==0.28.1)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from openai==0.28.1)\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting aiohttp (from openai==0.28.1)\n",
      "  Using cached aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.20->openai==0.28.1)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.20->openai==0.28.1)\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.20->openai==0.28.1)\n",
      "  Using cached urllib3-2.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.20->openai==0.28.1)\n",
      "  Using cached certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->openai==0.28.1)\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->openai==0.28.1)\n",
      "  Using cached multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai==0.28.1)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->openai==0.28.1)\n",
      "  Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai==0.28.1)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->openai==0.28.1)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Using cached openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Installing collected packages: urllib3, tqdm, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.4\n",
      "    Uninstalling multidict-6.0.4:\n",
      "      Successfully uninstalled multidict-6.0.4\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.0\n",
      "    Uninstalling frozenlist-1.4.0:\n",
      "      Successfully uninstalled frozenlist-1.4.0\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.11.17\n",
      "    Uninstalling certifi-2023.11.17:\n",
      "      Successfully uninstalled certifi-2023.11.17\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 4.0.3\n",
      "    Uninstalling async-timeout-4.0.3:\n",
      "      Successfully uninstalled async-timeout-4.0.3\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.4\n",
      "    Uninstalling yarl-1.9.4:\n",
      "      Successfully uninstalled yarl-1.9.4\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.9.1\n",
      "    Uninstalling aiohttp-3.9.1:\n",
      "      Successfully uninstalled aiohttp-3.9.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.1\n",
      "    Uninstalling openai-0.28.1:\n",
      "      Successfully uninstalled openai-0.28.1\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 certifi-2023.11.17 charset-normalizer-3.3.2 frozenlist-1.4.0 idna-3.6 multidict-6.0.4 openai-0.28.1 requests-2.31.0 tqdm-4.66.1 urllib3-2.1.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyodbc\n",
    "%pip install python-dotenv\n",
    "%pip install --upgrade --force-reinstall openai==0.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the required environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create code to handle connecting to the database\n",
    "The settings for the database should obviously be in a config file, but for now I'm just going to hard code them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MSSQL database\n",
    "import pyodbc\n",
    "\n",
    "SERVER = '127.0.0.1'\n",
    "DATABASE = 'TestDb'\n",
    "USERNAME = 'sa'\n",
    "PASSWORD = 'Password123'\n",
    "\n",
    "connectionString = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD}'\n",
    "\n",
    "conn = pyodbc.connect(connectionString)\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all table definitions\n",
    "The table information will be passed to the AI prompt so it can create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table names\n",
    "get_all_tables_stmt = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES;\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(get_all_tables_stmt)\n",
    "table_names = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Get all table definitions and format them into CREATE TABLE statements\n",
    "get_def_stmt = f\"\"\"\n",
    "SELECT COLUMN_NAME, DATA_TYPE\n",
    "FROM INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE TABLE_NAME = ?\n",
    "\"\"\"\n",
    "\n",
    "definitions = []\n",
    "for table_name in table_names:\n",
    "    cursor.execute(get_def_stmt, (table_name,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    create_table_stmt = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    for row in rows:\n",
    "        create_table_stmt += f\"{row[0]} {row[1]},\\n\"\n",
    "    create_table_stmt = create_table_stmt.rstrip(\",\\n\") + \"\\n);\"\n",
    "    \n",
    "    definitions.append(create_table_stmt)\n",
    "\n",
    "table_definitions = \"\\n\\n\".join(definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the user input\n",
    "user_question = \"How many users are there in the database?\"\n",
    "\n",
    "# The rest of this prompt building is back end logic\n",
    "## Build the request\n",
    "prompt = f\"Fulfill this database query: {user_question}. \"\n",
    "POSTGRES_TABLE_DEFINITIONS_CAP_REF = \"TABLE_DEFINITIONS\"\n",
    "prompt_suffix = f\"Use these {POSTGRES_TABLE_DEFINITIONS_CAP_REF} to satisfy the database query.\"\n",
    "\n",
    "prompt = f\"\"\"{prompt} {prompt_suffix}\\n\\n{POSTGRES_TABLE_DEFINITIONS_CAP_REF}\\n\\n{table_definitions}\"\"\"\n",
    "\n",
    "## Append the response format\n",
    "SQL_DELIMITER = \"---------\"\n",
    "RESPONSE_FORMAT_CAP_REF = \"RESPONSE_FORMAT\"\n",
    "prompt_suffix = f\"\\n\\nRespond in this format {RESPONSE_FORMAT_CAP_REF}. Replace the text between <> with it's request. I need to be able to easily parse the sql query from your response.\"\n",
    "cap_ref_content = f\"\"\"<explanation of the sql query>\n",
    "{SQL_DELIMITER}\n",
    "<sql query exclusively as raw text>\"\"\"\n",
    "prompt = f\"\"\"{prompt} {prompt_suffix}\\n\\n{RESPONSE_FORMAT_CAP_REF}\\n\\n{cap_ref_content}\"\"\"\n",
    "\n",
    "print(\"\\n\\n-------- PROMPT --------\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send the prompt to the AI model\n",
    "NOTE: I had to pin the openai version to 0.28 becuase the 1.0 version has breaking changes.  To keep this example short I did not want to go through the migration guide.\n",
    "https://github.com/openai/openai-python/discussions/742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------- RESPONSE --------\n",
      "{\n",
      "  \"id\": \"chatcmpl-8SsLY8s8a2HiTncm1vdlNaRrjMyhG\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1701892784,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The SQL query counts the number of unique user IDs in the tblUsers table. We use the COUNT function with the DISTINCT keyword to ensure that each individual user is only counted once, even if they may appear multiple times in the table.\\n---------\\nSELECT COUNT(DISTINCT id) FROM tblUsers;\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 449,\n",
      "    \"completion_tokens\": 59,\n",
      "    \"total_tokens\": 508\n",
      "  },\n",
      "  \"system_fingerprint\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "model = \"gpt-4\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\n\\n-------- RESPONSE --------\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the response and extract the SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------- PARSED SQL QUERY --------\n",
      "SELECT COUNT(DISTINCT id) FROM tblUsers;\n"
     ]
    }
   ],
   "source": [
    "# This was taken directly from the example.  I need to review it later.\n",
    "def safe_get(data, dot_chained_keys):\n",
    "    \"\"\"\n",
    "    {'a': {'b': [{'c': 1}]}}\n",
    "    safe_get(data, 'a.b.0.c') -> 1\n",
    "    \"\"\"\n",
    "    keys = dot_chained_keys.split(\".\")\n",
    "    for key in keys:\n",
    "        try:\n",
    "            if isinstance(data, list):\n",
    "                data = data[int(key)]\n",
    "            else:\n",
    "                data = data[key]\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "            return None\n",
    "    return data\n",
    "\n",
    "prompt_response = safe_get(response, \"choices.0.message.content\")\n",
    "\n",
    "sql_query = prompt_response.split(SQL_DELIMITER)[1].strip()\n",
    "\n",
    "print(f\"\\n\\n-------- PARSED SQL QUERY --------\")\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the query and print the results\n",
    "Also make sure to close the database connection here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-------- SQL QUERY RESULTS --------\n",
      "[(150,)]\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "rows = cursor.fetchall()\n",
    "print(f\"\\n\\n-------- SQL QUERY RESULTS --------\")\n",
    "print(rows)\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
