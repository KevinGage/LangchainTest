{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is part 4 of using autogen with local ai models to query an arbitrary database.\n",
    "In this notebook I will use autogen with ChatGPT to connect to a local database and query it.  I will try this with a few local AI models\n",
    "I'm using this reference https://github.com/disler/multi-agent-postgres-data-analytics/tree/v1-prompt-engineering-an-entire-codebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyodbc\n",
    "%pip install python-dotenv\n",
    "%pip install pyautogen\n",
    "%pip install --upgrade --force-reinstall openai==0.28.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the required environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_BASE = os.environ.get(\"OPENAI_API_BASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create code to handle connecting to the database\n",
    "The settings for the database should obviously be in a config file, but for now I'm just going to hard code them in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MSSQL database\n",
    "import pyodbc\n",
    "\n",
    "SERVER = '127.0.0.1'\n",
    "DATABASE = 'TimeBasedCommitments'\n",
    "USERNAME = 'sa'\n",
    "PASSWORD = 'BadDefaultPassword!'\n",
    "\n",
    "connectionString = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD}'\n",
    "\n",
    "conn = pyodbc.connect(connectionString)\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all table definitions\n",
    "The table information will be passed to the AI prompt so it can create queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table names\n",
    "get_all_tables_stmt = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES;\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(get_all_tables_stmt)\n",
    "table_names = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Get all table definitions and format them into CREATE TABLE statements\n",
    "get_def_stmt = f\"\"\"\n",
    "SELECT COLUMN_NAME, DATA_TYPE\n",
    "FROM INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE TABLE_NAME = ?\n",
    "\"\"\"\n",
    "\n",
    "definitions = []\n",
    "for table_name in table_names:\n",
    "    cursor.execute(get_def_stmt, (table_name,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    create_table_stmt = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    for row in rows:\n",
    "        create_table_stmt += f\"{row[0]} {row[1]},\\n\"\n",
    "    create_table_stmt = create_table_stmt.rstrip(\",\\n\") + \"\\n);\"\n",
    "    \n",
    "    definitions.append(create_table_stmt)\n",
    "\n",
    "table_definitions = \"\\n\\n\".join(definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a function that agent can use to run SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(sql):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    print(f\"\\n\\n-------- SQL QUERY RESULTS --------\")\n",
    "    print(rows)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the AI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "# build the gpt_configuration object\n",
    "gpt4_config = {\n",
    "    \"use_cache\": False,\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": autogen.config_list_from_models([\"gpt-4\"]),\n",
    "    \"request_timeout\": 120,\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"run_sql\",\n",
    "            \"description\": \"Run a SQL query against the postgres database\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"sql\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The SQL query to run\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"sql\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# build the function map to make functions available to some autogen agents\n",
    "function_map = {\n",
    "    \"run_sql\": run_sql,\n",
    "}\n",
    "\n",
    "# create our terminate msg function\n",
    "def is_termination_msg(content):\n",
    "    have_content = content.get(\"content\", None) is not None\n",
    "    if have_content and \"APPROVED\" in content[\"content\"]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "COMPLETION_PROMPT = \"If everything looks good, respond with APPROVED\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_PROXY_PROMPT = (\n",
    "    \"A human admin. Interact with the Product Manager to discuss the plan. Plan execution needs to be approved by this admin.\"\n",
    "    + COMPLETION_PROMPT\n",
    ")\n",
    "DATA_ENGINEER_PROMPT = (\n",
    "    \"A Data Engineer. You follow an approved plan. Generate the initial SQL based on the requirements provided. Send it to the Sr Data Analyst to be executed.\"\n",
    "    + COMPLETION_PROMPT\n",
    ")\n",
    "SR_DATA_ANALYST_PROMPT = (\n",
    "    \"Sr Data Analyst. You follow an approved plan. You run the SQL query, generate the response and send it to the product manager for final review.\"\n",
    "    + COMPLETION_PROMPT\n",
    ")\n",
    "PRODUCT_MANAGER_PROMPT = (\n",
    "    \"Product Manager. Validate the response to make sure it's correct\"\n",
    "    + COMPLETION_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the agent roles/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of agents with specific roles\n",
    "# admin user proxy agent - takes in the prompt and manages the group chat\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=USER_PROXY_PROMPT,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=is_termination_msg,\n",
    ")\n",
    "\n",
    "# data engineer agent - generates the sql query\n",
    "data_engineer = autogen.AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=DATA_ENGINEER_PROMPT,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=is_termination_msg,\n",
    ")\n",
    "\n",
    "# sr data analyst agent - run the sql query and generate the response\n",
    "sr_data_analyst = autogen.AssistantAgent(\n",
    "    name=\"Sr_Data_Analyst\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=SR_DATA_ANALYST_PROMPT,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=is_termination_msg,\n",
    "    function_map=function_map,\n",
    ")\n",
    "\n",
    "# product manager - validate the response to make sure it's correct\n",
    "product_manager = autogen.AssistantAgent(\n",
    "    name=\"Product_Manager\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=PRODUCT_MANAGER_PROMPT,\n",
    "    code_execution_config=False,\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=is_termination_msg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the group chat and add the agents to the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, data_engineer, sr_data_analyst, product_manager],\n",
    "    messages=[],\n",
    "    max_round=10,\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt the group and initiate the chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"how many users are in the database?\"\n",
    "\n",
    "prompt = f\"Fulfill this database query: {user_question}. \"\n",
    "\n",
    "# add the database info to the prompt\n",
    "POSTGRES_TABLE_DEFINITIONS_CAP_REF = \"TABLE_DEFINITIONS\"\n",
    "prompt_suffix = f\"Use these {POSTGRES_TABLE_DEFINITIONS_CAP_REF} to satisfy the database query.\"\n",
    "\n",
    "prompt = f\"\"\"{prompt} {prompt_suffix}\\n\\n{POSTGRES_TABLE_DEFINITIONS_CAP_REF}\\n\\n{table_definitions}\"\"\"\n",
    "\n",
    "# initiate the chat\n",
    "result = user_proxy.initiate_chat(manager, clear_history=True, message=prompt)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The local models were either too slow or too inaccurate to be useful.  Mixtral shows the most promise but my laptop doesnt have enough VRAM to hold the whole model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
