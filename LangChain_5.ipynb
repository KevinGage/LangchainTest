{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is part 1 of using langchain with local ai models to query an arbitrary database.\n",
    "In this notebook I will try to use langchain with local models to generate a SQL query, run the query, then format the results into natural language.  I will be using the other unnumbered langchain notebooks as a reference.  I'll also be using some of the logic from the previous autogen notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install langchain\n",
    "%pip install pip install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to MSSQL database\n",
    "import pyodbc\n",
    "\n",
    "SERVER = '127.0.0.1'\n",
    "DATABASE = 'TimeBasedCommitments'\n",
    "USERNAME = 'sa'\n",
    "PASSWORD = 'BadDefaultPassword!'\n",
    "\n",
    "connectionString = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={SERVER};DATABASE={DATABASE};UID={USERNAME};PWD={PASSWORD}'\n",
    "\n",
    "conn = pyodbc.connect(connectionString)\n",
    "\n",
    "# conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch database schema to use as context for AI prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get table names\n",
    "get_all_tables_stmt = \"SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES;\"\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(get_all_tables_stmt)\n",
    "table_names = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "# Get all table definitions and format them into CREATE TABLE statements\n",
    "get_def_stmt = f\"\"\"\n",
    "SELECT COLUMN_NAME, DATA_TYPE\n",
    "FROM INFORMATION_SCHEMA.COLUMNS\n",
    "WHERE TABLE_NAME = ?\n",
    "\"\"\"\n",
    "\n",
    "definitions = []\n",
    "for table_name in table_names:\n",
    "    cursor.execute(get_def_stmt, (table_name,))\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    create_table_stmt = f\"CREATE TABLE {table_name} (\\n\"\n",
    "    for row in rows:\n",
    "        create_table_stmt += f\"{row[0]} {row[1]},\\n\"\n",
    "    create_table_stmt = create_table_stmt.rstrip(\",\\n\") + \"\\n);\"\n",
    "    \n",
    "    definitions.append(create_table_stmt)\n",
    "\n",
    "table_definitions = \"\\n\\n\".join(definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://localhost:5001/api/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "KOBOLD_API_BASE = os.getenv('KOBOLD_API_BASE')\n",
    "print(KOBOLD_API_BASE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build AI prompt used to request a SQL query\n",
    "This prompt seemed to work well with mixtrel.  It uses the recommended prompt format from here https://huggingface.co/TheBloke/Mixtral-8x7B-Instruct-v0.1-GGUF.\n",
    "I may want to enhance this by specifying that the query should return names and not ids.\n",
    "I may also want to split out the template a bit so I don't rebuild the template each time I create a prompt.\n",
    "The model keeps escaping _ characters with \\ in its response so I had to strip them out. Asking it to not use \\ in the prompt only helped sometimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT TOP 1 completed_by, COUNT(*) as num_completions\n",
      "FROM tblSpecificCommitments\n",
      "WHERE completed IS NOT NULL\n",
      "GROUP BY completed_by\n",
      "ORDER BY num_completions DESC;\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import KoboldApiLLM\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = KoboldApiLLM(endpoint=KOBOLD_API_BASE, temperature=0.1, )\n",
    "\n",
    "template = \"\"\"[INST]\n",
    "Create a SQL query that can be used to answer this question: {question}\n",
    "\n",
    "Use these TABLE_DEFINITIONS to satisfy the database query.\n",
    "\n",
    "[TABLE_DEFINITIONS]\n",
    "{table_definitions}\n",
    "[/TABLE_DEFINITIONS]\n",
    "\n",
    "Respond only with the SQL query as raw text. I need to be able to easily parse the sql query from your response.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"table_definitions\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"Who completed the most specific commitments?\"\n",
    "\n",
    "sql_query = llm_chain.run(question = question, table_definitions = table_definitions)\n",
    "\n",
    "# remove all isntances of \\ in the sql query\n",
    "sql_query = sql_query.replace(\"\\\\\", \"\")\n",
    "\n",
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the SQL query\n",
    "I should wrap this in a loop.  That way if the query fails to run I can generate a new one and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1)]\n"
     ]
    }
   ],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(sql_query)\n",
    "rows = cursor.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, the individual who completed the most specific commitments is the one with the ID of 1, who has completed a total of 1 commitment. Since there are no other records in the result set, it can be assumed that no other individuals have completed any specific commitments at this time.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"[INST]\n",
    "Answer this question: {question}\n",
    "\n",
    "Assume this SQL query was run: {sql_query}\n",
    "\n",
    "Assume this was the data returned from the query: {data}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\", \"sql_query\", \"data\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "response = llm_chain.run(question = question, sql_query = sql_query, data = rows)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "winvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
